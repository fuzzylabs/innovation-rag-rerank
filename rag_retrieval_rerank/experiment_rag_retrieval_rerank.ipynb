{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RAG Rerank Retrieval Experiment\n",
    "\n",
    "In this experiment, we will experiment with pure document retrieval without reranking, as typically found in Naive RAG systems, and compare it to the improvements achieved by utlilsing reranking. \n",
    "\n",
    "Reranking is a technique that can dramatically optimise our retrieval pipelines and enhance their accuracy. To learn more about how reranking works and the challenges it addresses, visit [this](https://www.notion.so/fuzzylabs/Reranking-04e3f64f27724e51875abd7eb7d97a3c#6f1682a7b243482a8d226f675816851c) notion page.\n",
    "\n",
    "In this example notebook, we will demonstrate how to create retrieval pipelines with reranking using the [BAAI/bge-reranker-large](https://huggingface.co/BAAI/bge-reranker-large) reranker, which has comparable performance to Cohere's paid model, according to Llamaindex.\n",
    "\n",
    "The following components are used:\n",
    "- VectorDB - [Pinecone](https://www.pinecone.io/)\n",
    "- Embedding Model - [jinaai/jina-embeddings-v2-base-en](https://huggingface.co/jinaai/jina-embeddings-v2-base-en)\n",
    "- Reranker - [BAAI/bge-reranker-large](https://huggingface.co/BAAI/bge-reranker-large)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters\n",
    "The following parameters are used in the experiment.\n",
    "   \n",
    "`QUERY = \"Who manufactured STM32F429ZIT6U microcontroller?\"`\n",
    "\n",
    "We have chosen the above query to check for specific content within the context and to evaluate improvements after applying reranking to the retrieval results.\n",
    "\n",
    "Specifically, we are looking for following content in the retrieved documents.\n",
    "\n",
    "`In this chapter, many programs were developed using the NUCLEO board, provided with the STM32F429ZIT6U microcontroller. This microcontroller is manufactured by STMicroelectronics [13] using a Cortex-M4 processor designed by Arm Ltd. [14].`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "######## Parameters #########\n",
    "\n",
    "# Data\n",
    "FILE_PATH = \"data/a_beginners_guide_to_designing_embedded_system_applications_on_arm_cortex-m_microcontrollers.pdf\"\n",
    "CHUNK_SIZE = 1000\n",
    "CHUNK_OVERLAP = 50\n",
    "COLLECTION_NAME = 'experiment_search'\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "# Embedding model\n",
    "EMBEDDING_MODEL = \"jinaai/jina-embeddings-v2-base-en\"\n",
    "\n",
    "# Reranker\n",
    "RERANKER_MODEL = 'BAAI/bge-reranker-large'\n",
    "\n",
    "# Query\n",
    "TOP_K = 3\n",
    "QUERY = \"Who manufactured STM32F429ZIT6U microcontroller?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to utilise GPU to speed up computation time if available.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device=cpu\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "DEVICE = 'cuda:0' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device={DEVICE}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "> Make sure the pdf data is present in [data](data) folder.\n",
    "\n",
    "In this step, we preprocess the our example PDF data defined by FILE_PATH parameter. This pre-processed data will be added in the vector store.\n",
    "\n",
    "- We use [PyPDFLoader](https://python.langchain.com/v0.1/docs/modules/data_connection/document_loaders/pdf/#using-pypdf) from langchain to read the PDF.\n",
    "- We use [RecursiveCharacterTextSplitter](https://python.langchain.com/v0.1/docs/modules/data_connection/document_transformers/recursive_text_splitter/) from langchain to split the text in small chunks. The parameters `CHUNK_SIZE` and `CHUNK_OVERLAP` configure the chunk size and chunk overlap.\n",
    "> This step takes about 3 mins for a 600 pages PDF document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 42s, sys: 3.93 s, total: 2min 46s\n",
      "Wall time: 3min 6s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from data_pipeline import prepare_data\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size=CHUNK_SIZE,\n",
    "    chunk_overlap=CHUNK_OVERLAP,\n",
    "    length_function=len,\n",
    "    is_separator_regex=False,\n",
    ")\n",
    "chunked_texts = prepare_data(FILE_PATH, text_splitter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embedding The Data\n",
    "\n",
    "In this step, we will use Jina AI's embedding model to embed all of our texts and create a pandas DataFrame to associate the embeddings with their corresponding texts.\n",
    "\n",
    "> This step is resource intensive and it's much faster on Nvidia GPU.\n",
    ">\n",
    "> It might take around 10-15 mins if running on CPU.\n",
    ">\n",
    "> It calculates the embeddings for entire dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/oscar/Library/Caches/pypoetry/virtualenvs/rag-retrieval-rerank-_oC8k4Cq-py3.10/lib/python3.10/site-packages/sentence_transformers/cross_encoder/CrossEncoder.py:11: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 51min 30s, sys: 3min 50s, total: 55min 20s\n",
      "Wall time: 15min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "from embedding_model import embed_locally\n",
    "\n",
    "text_embeddings = embed_locally(chunked_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data_to_store = pd.DataFrame({'embeddings': text_embeddings})\n",
    "data_to_store['metadata'] = [{'texts': text} for text in chunked_texts]\n",
    "data_to_store.index.name = 'id'\n",
    "data_to_store.reset_index(inplace=True)\n",
    "data_to_store['id'] = data_to_store['id'].astype(str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> We include a metadata column containing the corresponding embedding texts in a dictionary because Pinecone cannot store strings directly and only allows text within the metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>metadata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>[-0.022770140320062637, -0.049992650747299194,...</td>\n",
       "      <td>{'texts': 'A Beginner’s Guide to Designing \n",
       "Em...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>[-0.04170405492186546, -0.04468979313969612, 0...</td>\n",
       "      <td>{'texts': 'A Beginner’s Guide to  \n",
       "Designing E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[-0.036007110029459, -0.06197873130440712, 0.0...</td>\n",
       "      <td>{'texts': 'A Beginner’s Guide to  Designing \n",
       "E...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>[-0.028807535767555237, -0.03928277641534805, ...</td>\n",
       "      <td>{'texts': 'Arm Education Media is an imprint o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>[-0.012164550833404064, -0.04263245314359665, ...</td>\n",
       "      <td>{'texts': 'book.\n",
       "Notices\n",
       "Knowledge and best pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1630</th>\n",
       "      <td>1630</td>\n",
       "      <td>[-0.04276715964078903, -0.048491425812244415, ...</td>\n",
       "      <td>{'texts': 'ISBN 978-1911531-16-6 \n",
       "Operating Sy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1631</th>\n",
       "      <td>1631</td>\n",
       "      <td>[-0.03923221305012703, -0.051492903381586075, ...</td>\n",
       "      <td>{'texts': 'A Beginner’s Guide to Designing \n",
       "Em...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1632</th>\n",
       "      <td>1632</td>\n",
       "      <td>[-0.04426056891679764, -0.06682316213846207, 0...</td>\n",
       "      <td>{'texts': 'align with a typical twelve-week se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1633</th>\n",
       "      <td>1633</td>\n",
       "      <td>[-0.052978359162807465, -0.04494466632604599, ...</td>\n",
       "      <td>{'texts': 'Arm Education Media is a publishing...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1634</th>\n",
       "      <td>1634</td>\n",
       "      <td>[-0.03897389397025108, 0.0006498997681774199, ...</td>\n",
       "      <td>{'texts': 'Journal, published by the School of...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1635 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                         embeddings  \\\n",
       "0        0  [-0.022770140320062637, -0.049992650747299194,...   \n",
       "1        1  [-0.04170405492186546, -0.04468979313969612, 0...   \n",
       "2        2  [-0.036007110029459, -0.06197873130440712, 0.0...   \n",
       "3        3  [-0.028807535767555237, -0.03928277641534805, ...   \n",
       "4        4  [-0.012164550833404064, -0.04263245314359665, ...   \n",
       "...    ...                                                ...   \n",
       "1630  1630  [-0.04276715964078903, -0.048491425812244415, ...   \n",
       "1631  1631  [-0.03923221305012703, -0.051492903381586075, ...   \n",
       "1632  1632  [-0.04426056891679764, -0.06682316213846207, 0...   \n",
       "1633  1633  [-0.052978359162807465, -0.04494466632604599, ...   \n",
       "1634  1634  [-0.03897389397025108, 0.0006498997681774199, ...   \n",
       "\n",
       "                                               metadata  \n",
       "0     {'texts': 'A Beginner’s Guide to Designing \n",
       "Em...  \n",
       "1     {'texts': 'A Beginner’s Guide to  \n",
       "Designing E...  \n",
       "2     {'texts': 'A Beginner’s Guide to  Designing \n",
       "E...  \n",
       "3     {'texts': 'Arm Education Media is an imprint o...  \n",
       "4     {'texts': 'book.\n",
       "Notices\n",
       "Knowledge and best pr...  \n",
       "...                                                 ...  \n",
       "1630  {'texts': 'ISBN 978-1911531-16-6 \n",
       "Operating Sy...  \n",
       "1631  {'texts': 'A Beginner’s Guide to Designing \n",
       "Em...  \n",
       "1632  {'texts': 'align with a typical twelve-week se...  \n",
       "1633  {'texts': 'Arm Education Media is a publishing...  \n",
       "1634  {'texts': 'Journal, published by the School of...  \n",
       "\n",
       "[1635 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_to_store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Vector Database with Pinecone\n",
    "\n",
    "\n",
    "Now we create our vector DB to store our vectors. For this we need to get a [free Pinecone API key](https://app.pinecone.io/) — the API key can be found in the \"API Keys\" button found in the left navbar of the Pinecone dashboard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "import time\n",
    "import getpass\n",
    "\n",
    "# initialise connection to pinecone (get API key at app.pinecone.io)\n",
    "api_key = getpass.getpass()\n",
    "\n",
    "# configure client\n",
    "pc = Pinecone(api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> An \"Index\" is a database in Pinecone."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 768,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {},\n",
       " 'total_vector_count': 0}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_name = \"rerankers\"\n",
    "existing_indexes = [\n",
    "    index_info[\"name\"] for index_info in pc.list_indexes()\n",
    "]\n",
    "\n",
    "# check if index already exists (it shouldn't if this is first time)\n",
    "if index_name not in existing_indexes:\n",
    "    # if does not exist, create index\n",
    "    pc.create_index(\n",
    "        index_name,\n",
    "        dimension=768,  # embedding dimensionality of jina-embeddings-v2-base\n",
    "        metric='cosine',\n",
    "        spec=ServerlessSpec(\n",
    "            cloud=\"aws\", region=\"us-east-1\"\n",
    "        )\n",
    "    )\n",
    "    # wait for index to be initialized\n",
    "    while not pc.describe_index(index_name).status['ready']:\n",
    "        time.sleep(1)\n",
    "\n",
    "# connect to index\n",
    "index = pc.Index(index_name)\n",
    "# view index stats\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Ingestion\n",
    "\n",
    "In this step, we store the embeddings and chunked texts in the Pinecone database we just created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 17/17 [00:11<00:00,  1.50it/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "\n",
    "batch_size = 100  # how many embeddings we create and insert at once\n",
    "\n",
    "for i in tqdm(range(0, len(data_to_store), batch_size)):\n",
    "    passed = False\n",
    "    # find end of batch\n",
    "    i_end = min(len(data_to_store), i+batch_size)\n",
    "    # create batch\n",
    "    batch = data_to_store[i:i_end]\n",
    "    to_upsert = list(zip(batch[\"id\"], batch[\"embeddings\"], batch[\"metadata\"]))\n",
    "\n",
    "    # upsert to Pinecone\n",
    "    index.upsert(vectors=to_upsert)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Retrieval\n",
    "\n",
    "Now that we have our chunked texts and their embeddings stored in the database, we can retrieve them from Pinecone by calling the query function. The steps are as follows:\n",
    "\n",
    "1. Embed our query.\n",
    "2. Call the query function on the Pinecone index object.\n",
    "3. Return the text from the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closest_texts(query: str, top_k: int) -> list[tuple[str, float]]:\n",
    "    # encode query\n",
    "    encoded_query = embed_locally([query])\n",
    "    # search Pinecone index\n",
    "    res = index.query(vector=encoded_query[0], top_k=top_k, include_metadata=True)\n",
    "    # get doc text\n",
    "    closest_texts = [(match[\"metadata\"]['texts'], match[\"score\"]) for match in res[\"matches\"]]\n",
    "    return closest_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval With No Reranking (Naive RAG Retrieval)\n",
    "\n",
    "This is the most common approach for retrieving semantically similar documents to the query with, these embeddings are also known as dense vector. The dense vector captures the semantic meaning of the text using the embedding model.\n",
    "\n",
    "The query vector is matched against all the entries in the database to find closest neighbors to the search query using a distance metric, in this case, the cosine distance.\n",
    "\n",
    "Typically, we will look for the 3 closest documents in the database. These 3 documents will be pass to a LLM to be used as contexts to generate a response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "three_closest_texts = get_closest_texts(query=QUERY, top_k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Retrieved Document</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Index\\n567 STM 32F429 ZIT 6U microcontroller 5, 33, 37, 38 \\n stop bit 46, 64, 65, 80, 256 , 257 , 273 , 468  \\n ST Zio connectors xiv, 6, 9, 37, 38, 44, 346  \\n superloop 13, 519  \\n synchronous communication 255\\nT TCP server 456 , 457 , 459 , 460 –463 , 491  \\n temperature sensor 4, 5, 87, 106 , 123 , 182 , 220 , 233 , 334 , 486 , 550  \\n time management xvi, 86, 95, 99, 289 , 342 , 348 , 353  \\n timers xvi, xxvii, 37, 306 , 342 , 343 , 345 , 348 –350 , 353 , 354 , \\n 361 , 441 , 512 –517 , 533 , 535 , 537 , 538 , 539  \\n tm structure 153  \\n TO- 220  package 89\\nU UART xvi, xvii, 5, 44, 61, 63, 79, 82, 84, 86, 181 , 191 , 222 , 255 , 290 , 291 , \\n 306 , 350 , 420 , 423 , 447 , 455 , 461 , 465 , 468 , 544  \\n USB xiv, xxvii, 4, 9, 37, 44, 45, 63, 79, 82, 88, 132 , 449 , 506 , 507 , 508 , 544  \\n USB connection xiv, 44, 506  \\n use cases 497 , 501 –504 , 511 , 545 , 546 , 547 , 548\\nV validation 496 , 497 , 546 , 547  \\n verification 81, 92, 496 , 497 , 546  \\n vineyard frost prevention 123 , 124</td>\n",
       "      <td>0.824654</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Chapter 1 | Introduction to Embedded Systems \\n37The STM32F429ZIT6U microcontroller includes a Cortex-M4 processor , as shown in Figure 1.22. It \\ncan be appreciated that, beyond the processor, the microcontroller includes other peripherals such as \\ncommunication cores (ethernet, USB, UART, etc.), memory, timers, and GPIO (General Purpose Input Output) ports. \\nNUCLEO\\n-F429ZI32F429ZIT6U\\nARM7B776 VQ\\nPHL 7B 7213e412000K620 Y12000\\nK620 Y\\n120 00K620 YDGKYD\\nKMS-1 102NL1706C\\nSTM32F103CBT6\\ne393701GH218CHN\\nST890C\\nGK717\\n11\\n22\\n33\\n44\\n55\\n66\\n77\\n88\\n9\\n10\\n11\\n12\\n13\\n14\\n15PH_0\\nPD_0\\nPD_1\\nPG_0PH_1PF_2PA_7PF_10PF_5PF_3PC_3PC_030\\n29\\n28\\n27\\n2616\\n2515\\n2414\\n2313\\n2212\\n2111\\n2010\\n199\\n18\\n17\\n165V\\nVIN3.3VIOREF\\nGND\\nGNDGND\\nNCNC\\nUART2_RX\\nCAN1_TDCAN1_ DRADC1/7ADC1/3\\nADC1/10\\nADC1/13\\nADC3/9\\nADC3/15\\nADC3/8\\nADC3/5NRSTPC_8\\nPC_9\\nPC_10\\nPC_11\\nPC_12\\nPD_2\\nPG_2\\nPG_3\\nGNDPD_7\\nPD_6\\nPD_5\\nPD_4\\nPD_3\\nPE_2\\nPE_4\\nPE_3\\nPF_7\\nPG_1UART2_RX\\nUART2_ XT\\nUART_X7TUART2_RTS\\nUART2_CTSUART3_TX\\nUART3_RX\\nUART5_TX\\nUART5_RX\\nPA_3\\nSPI1_MOSISPI3_SCK\\nSPI2_SCK</td>\n",
       "      <td>0.808520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>USAR Tn\\nbxCANnsmcard\\nirDA\\nFIFODigital\\nﬁlter\\nDACnAPB1 45 MHz (max)AHB1 180 MHzAHB3\\nVDD = 1.8 to 3.6V\\nVSS\\nVCAP1, VCAP2APB2 90 MHzART\\nACCEL/CACHE\\nGPIO POR TtOSC32_I N\\nOSC32_OUTDMA2USB\\nOTG HS\\n8 Streams\\nFIFODMA/\\nFIFO PHY\\nCHROM-AR T\\nDMA2DFIFO\\nFIFO8 Streams\\nFIFODMA1\\nLCD_R[7:0], LCD_G[7:0] ,\\nLCD_B[7:0], LCD_HSYNC,\\nLCD_VSYNC, LCD_DE,\\nLCD_CLKLCD-TFTDMA/\\nFIFO\\nRTC_AF1\\nRTC_AF1\\nRTC 50Hz\\n4KB BXPSRAMLS@ VBAT\\nRTC\\nAWU\\nBackup registerXTAL32 KHz\\nLSStandby\\ninterfaceIWDGXTALOSC 4-26 MHzPOR\\nreset\\nInt\\n@ VDDA @ VDDPVDPOR/PDR BORSupply\\nsupervision@ VDDVDD\\nVoltage regulator\\n3.3 to 1.2VPower\\nmanagement\\nPLL1, 2, 3RC    LSRC    HS@ VDDA\\nReset\\n&amp; clock\\ncontrol\\nFigure 1.22 STM32F429ZI block diagram made using information available from [9].</td>\n",
       "      <td>0.807650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                      Retrieved Document  \\\n",
       "0                                                                 Index\\n567 STM 32F429 ZIT 6U microcontroller 5, 33, 37, 38 \\n stop bit 46, 64, 65, 80, 256 , 257 , 273 , 468  \\n ST Zio connectors xiv, 6, 9, 37, 38, 44, 346  \\n superloop 13, 519  \\n synchronous communication 255\\nT TCP server 456 , 457 , 459 , 460 –463 , 491  \\n temperature sensor 4, 5, 87, 106 , 123 , 182 , 220 , 233 , 334 , 486 , 550  \\n time management xvi, 86, 95, 99, 289 , 342 , 348 , 353  \\n timers xvi, xxvii, 37, 306 , 342 , 343 , 345 , 348 –350 , 353 , 354 , \\n 361 , 441 , 512 –517 , 533 , 535 , 537 , 538 , 539  \\n tm structure 153  \\n TO- 220  package 89\\nU UART xvi, xvii, 5, 44, 61, 63, 79, 82, 84, 86, 181 , 191 , 222 , 255 , 290 , 291 , \\n 306 , 350 , 420 , 423 , 447 , 455 , 461 , 465 , 468 , 544  \\n USB xiv, xxvii, 4, 9, 37, 44, 45, 63, 79, 82, 88, 132 , 449 , 506 , 507 , 508 , 544  \\n USB connection xiv, 44, 506  \\n use cases 497 , 501 –504 , 511 , 545 , 546 , 547 , 548\\nV validation 496 , 497 , 546 , 547  \\n verification 81, 92, 496 , 497 , 546  \\n vineyard frost prevention 123 , 124   \n",
       "1  Chapter 1 | Introduction to Embedded Systems \\n37The STM32F429ZIT6U microcontroller includes a Cortex-M4 processor , as shown in Figure 1.22. It \\ncan be appreciated that, beyond the processor, the microcontroller includes other peripherals such as \\ncommunication cores (ethernet, USB, UART, etc.), memory, timers, and GPIO (General Purpose Input Output) ports. \\nNUCLEO\\n-F429ZI32F429ZIT6U\\nARM7B776 VQ\\nPHL 7B 7213e412000K620 Y12000\\nK620 Y\\n120 00K620 YDGKYD\\nKMS-1 102NL1706C\\nSTM32F103CBT6\\ne393701GH218CHN\\nST890C\\nGK717\\n11\\n22\\n33\\n44\\n55\\n66\\n77\\n88\\n9\\n10\\n11\\n12\\n13\\n14\\n15PH_0\\nPD_0\\nPD_1\\nPG_0PH_1PF_2PA_7PF_10PF_5PF_3PC_3PC_030\\n29\\n28\\n27\\n2616\\n2515\\n2414\\n2313\\n2212\\n2111\\n2010\\n199\\n18\\n17\\n165V\\nVIN3.3VIOREF\\nGND\\nGNDGND\\nNCNC\\nUART2_RX\\nCAN1_TDCAN1_ DRADC1/7ADC1/3\\nADC1/10\\nADC1/13\\nADC3/9\\nADC3/15\\nADC3/8\\nADC3/5NRSTPC_8\\nPC_9\\nPC_10\\nPC_11\\nPC_12\\nPD_2\\nPG_2\\nPG_3\\nGNDPD_7\\nPD_6\\nPD_5\\nPD_4\\nPD_3\\nPE_2\\nPE_4\\nPE_3\\nPF_7\\nPG_1UART2_RX\\nUART2_ XT\\nUART_X7TUART2_RTS\\nUART2_CTSUART3_TX\\nUART3_RX\\nUART5_TX\\nUART5_RX\\nPA_3\\nSPI1_MOSISPI3_SCK\\nSPI2_SCK   \n",
       "2                                                                                                                                                                                                                                                                                                                             USAR Tn\\nbxCANnsmcard\\nirDA\\nFIFODigital\\nﬁlter\\nDACnAPB1 45 MHz (max)AHB1 180 MHzAHB3\\nVDD = 1.8 to 3.6V\\nVSS\\nVCAP1, VCAP2APB2 90 MHzART\\nACCEL/CACHE\\nGPIO POR TtOSC32_I N\\nOSC32_OUTDMA2USB\\nOTG HS\\n8 Streams\\nFIFODMA/\\nFIFO PHY\\nCHROM-AR T\\nDMA2DFIFO\\nFIFO8 Streams\\nFIFODMA1\\nLCD_R[7:0], LCD_G[7:0] ,\\nLCD_B[7:0], LCD_HSYNC,\\nLCD_VSYNC, LCD_DE,\\nLCD_CLKLCD-TFTDMA/\\nFIFO\\nRTC_AF1\\nRTC_AF1\\nRTC 50Hz\\n4KB BXPSRAMLS@ VBAT\\nRTC\\nAWU\\nBackup registerXTAL32 KHz\\nLSStandby\\ninterfaceIWDGXTALOSC 4-26 MHzPOR\\nreset\\nInt\\n@ VDDA @ VDDPVDPOR/PDR BORSupply\\nsupervision@ VDDVDD\\nVoltage regulator\\n3.3 to 1.2VPower\\nmanagement\\nPLL1, 2, 3RC    LSRC    HS@ VDDA\\nReset\\n& clock\\ncontrol\\nFigure 1.22 STM32F429ZI block diagram made using information available from [9].   \n",
       "\n",
       "      Score  \n",
       "0  0.824654  \n",
       "1  0.808520  \n",
       "2  0.807650  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "three_closest_texts_df = pd.DataFrame(three_closest_texts, columns=[\"Retrieved Document\", \"Score\"])\n",
    "three_closest_texts_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result\n",
    "The goal here is to verify if following context is present in any of the retrieved documents.\n",
    "\n",
    "> In this chapter, many programs were developed using the NUCLEO board, provided with the STM32F429ZIT6U microcontroller. This microcontroller is manufactured by STMicroelectronics [13] using a Cortex-M4 processor designed by Arm Ltd. [14].\n",
    "\n",
    "If it is present then our retrieval approach was able to find the correct document from the vector store.\n",
    "> It is not present in the any of retrieved documents."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieval With Reranking\n",
    "\n",
    "To convert texts into vectors, we are essentially compressing the \"meaning\" of the text into n-dimensional vectors. This compression results in some loss of information.\n",
    "\n",
    "Due to this information loss, the top three documents (for example) retrieved by a vector search may miss relevant details, which might fall below our top_k cutoff and not be returned, as demonstrated in the example above.\n",
    "\n",
    "Reranking addresses this issue by retrieving a larger initial set of documents from the database. A reranker then reorders these documents, retaining only the most relevant ones for our LLM.\n",
    "\n",
    "For a deeper understanding of how reranking works and the challenges it addresses, see [this](https://www.notion.so/fuzzylabs/Reranking-04e3f64f27724e51875abd7eb7d97a3c#6f1682a7b243482a8d226f675816851c) Notion page."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FlagEmbedding import FlagReranker\n",
    "reranker = FlagReranker('BAAI/bge-reranker-large', use_fp16=True) # Setting use_fp16 to True speeds up computation with a slight performance degradation\n",
    "\n",
    "\n",
    "def get_top_3_texts_from_rerank_scores(scores: list[float], closest_texts: list[str], top_k: int) -> list[str]:\n",
    "    top_k_indices = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:top_k]\n",
    "    return [closest_texts[i] for i in top_k_indices]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The bge reranker takes a list of list as input\n",
    "\n",
    "twenty_five_closest_texts = get_closest_texts(query=\"Who manufactured STM32F429ZIT6U microcontroller?\", top_k=25)\n",
    "texts_to_rerank = [[QUERY,doc[0]] for doc in twenty_five_closest_texts]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reranker Scores\n",
    "\n",
    "Below are the scores which represent the similarly between our query and the retrieved texts from our vector database. The higher the score, the more relevant the document is to our query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "TextInputSequence must be str",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[51], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m scores \u001b[38;5;241m=\u001b[39m \u001b[43mreranker\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_score\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts_to_rerank\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(scores)\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/rag-retrieval-rerank-_oC8k4Cq-py3.10/lib/python3.10/site-packages/torch/utils/_contextlib.py:115\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 115\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/rag-retrieval-rerank-_oC8k4Cq-py3.10/lib/python3.10/site-packages/FlagEmbedding/flag_reranker.py:207\u001b[0m, in \u001b[0;36mFlagReranker.compute_score\u001b[0;34m(self, sentence_pairs, batch_size, max_length, normalize)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m start_index \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m0\u001b[39m, \u001b[38;5;28mlen\u001b[39m(sentence_pairs), batch_size), desc\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCompute Scores\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    205\u001b[0m                         disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(sentence_pairs) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m128\u001b[39m):\n\u001b[1;32m    206\u001b[0m     sentences_batch \u001b[38;5;241m=\u001b[39m sentence_pairs[start_index:start_index \u001b[38;5;241m+\u001b[39m batch_size]\n\u001b[0;32m--> 207\u001b[0m     inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtokenizer\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m        \u001b[49m\u001b[43msentences_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    209\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    210\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    211\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    212\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    213\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m    215\u001b[0m     scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs, return_dict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\u001b[38;5;241m.\u001b[39mlogits\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, )\u001b[38;5;241m.\u001b[39mfloat()\n\u001b[1;32m    216\u001b[0m     all_scores\u001b[38;5;241m.\u001b[39mextend(scores\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39mtolist())\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/rag-retrieval-rerank-_oC8k4Cq-py3.10/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3055\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.__call__\u001b[0;34m(self, text, text_pair, text_target, text_pair_target, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, **kwargs)\u001b[0m\n\u001b[1;32m   3053\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_in_target_context_manager:\n\u001b[1;32m   3054\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_input_mode()\n\u001b[0;32m-> 3055\u001b[0m     encodings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_one\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtext\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtext_pair\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtext_pair\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mall_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3056\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m text_target \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3057\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_switch_to_target_mode()\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/rag-retrieval-rerank-_oC8k4Cq-py3.10/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3142\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase._call_one\u001b[0;34m(self, text, text_pair, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[0m\n\u001b[1;32m   3137\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   3138\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch length of `text`: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(text)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m does not match batch length of `text_pair`:\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3139\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(text_pair)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   3140\u001b[0m         )\n\u001b[1;32m   3141\u001b[0m     batch_text_or_text_pairs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mzip\u001b[39m(text, text_pair)) \u001b[38;5;28;01mif\u001b[39;00m text_pair \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m text\n\u001b[0;32m-> 3142\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbatch_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3143\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3144\u001b[0m \u001b[43m        \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3145\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpadding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3146\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtruncation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3147\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3148\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3149\u001b[0m \u001b[43m        \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3150\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3151\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3152\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3153\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3159\u001b[0m \u001b[43m        \u001b[49m\u001b[43msplit_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3160\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3162\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   3163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencode_plus(\n\u001b[1;32m   3164\u001b[0m         text\u001b[38;5;241m=\u001b[39mtext,\n\u001b[1;32m   3165\u001b[0m         text_pair\u001b[38;5;241m=\u001b[39mtext_pair,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3182\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3183\u001b[0m     )\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/rag-retrieval-rerank-_oC8k4Cq-py3.10/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:3338\u001b[0m, in \u001b[0;36mPreTrainedTokenizerBase.batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding, truncation, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens, **kwargs)\u001b[0m\n\u001b[1;32m   3328\u001b[0m \u001b[38;5;66;03m# Backward compatibility for 'truncation_strategy', 'pad_to_max_length'\u001b[39;00m\n\u001b[1;32m   3329\u001b[0m padding_strategy, truncation_strategy, max_length, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_padding_truncation_strategies(\n\u001b[1;32m   3330\u001b[0m     padding\u001b[38;5;241m=\u001b[39mpadding,\n\u001b[1;32m   3331\u001b[0m     truncation\u001b[38;5;241m=\u001b[39mtruncation,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   3335\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   3336\u001b[0m )\n\u001b[0;32m-> 3338\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_batch_encode_plus\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3339\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3340\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3341\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpadding_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpadding_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3342\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtruncation_strategy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtruncation_strategy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3343\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmax_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3344\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstride\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstride\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3345\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_split_into_words\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3346\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_to_multiple_of\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3347\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_tensors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_tensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_token_type_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_overflowing_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_special_tokens_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3352\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_offsets_mapping\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_length\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3355\u001b[0m \u001b[43m    \u001b[49m\u001b[43msplit_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msplit_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3356\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3357\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Library/Caches/pypoetry/virtualenvs/rag-retrieval-rerank-_oC8k4Cq-py3.10/lib/python3.10/site-packages/transformers/tokenization_utils_fast.py:528\u001b[0m, in \u001b[0;36mPreTrainedTokenizerFast._batch_encode_plus\u001b[0;34m(self, batch_text_or_text_pairs, add_special_tokens, padding_strategy, truncation_strategy, max_length, stride, is_split_into_words, pad_to_multiple_of, return_tensors, return_token_type_ids, return_attention_mask, return_overflowing_tokens, return_special_tokens_mask, return_offsets_mapping, return_length, verbose, split_special_tokens)\u001b[0m\n\u001b[1;32m    525\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tokenizer\u001b[38;5;241m.\u001b[39mencode_special_tokens \u001b[38;5;241m!=\u001b[39m split_special_tokens:\n\u001b[1;32m    526\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tokenizer\u001b[38;5;241m.\u001b[39mencode_special_tokens \u001b[38;5;241m=\u001b[39m split_special_tokens\n\u001b[0;32m--> 528\u001b[0m encodings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tokenizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencode_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    529\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_text_or_text_pairs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    530\u001b[0m \u001b[43m    \u001b[49m\u001b[43madd_special_tokens\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43madd_special_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    531\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_pretokenized\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_split_into_words\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    532\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    534\u001b[0m \u001b[38;5;66;03m# Convert encoding to dict\u001b[39;00m\n\u001b[1;32m    535\u001b[0m \u001b[38;5;66;03m# `Tokens` has type: Tuple[\u001b[39;00m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;66;03m#                       List[Dict[str, List[List[int]]]] or List[Dict[str, 2D-Tensor]],\u001b[39;00m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;66;03m#                       List[EncodingFast]\u001b[39;00m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;66;03m#                    ]\u001b[39;00m\n\u001b[1;32m    539\u001b[0m \u001b[38;5;66;03m# with nested dimensions corresponding to batch, overflows, sequence length\u001b[39;00m\n\u001b[1;32m    540\u001b[0m tokens_and_encodings \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m    541\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_convert_encoding(\n\u001b[1;32m    542\u001b[0m         encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    551\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m encoding \u001b[38;5;129;01min\u001b[39;00m encodings\n\u001b[1;32m    552\u001b[0m ]\n",
      "\u001b[0;31mTypeError\u001b[0m: TextInputSequence must be str"
     ]
    }
   ],
   "source": [
    "scores = reranker.compute_score(texts_to_rerank)\n",
    "print(scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Result\n",
    "\n",
    "The goal here is to verify if following context is present in any of the retrieved documents.\n",
    "\n",
    "> In this chapter, many programs were developed using the NUCLEO board, provided with the STM32F429ZIT6U microcontroller. This microcontroller is manufactured by STMicroelectronics [13] using a Cortex-M4 processor designed by Arm Ltd. [14].\n",
    "\n",
    "If it is present then our retrieval approach was able to find the correct document from the vector store.\n",
    "\n",
    "> It is present in the second row of Retrieved text in the first result as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_top_3_texts_from_rerank_scores(scores, twenty_five_closest_texts, top_k=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also visualise the relevance score for all 25 texts we have retrieved.\n",
    "\n",
    "The reranker is optimised based cross-entropy loss, so the relevance score is not bounded to a specific range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_for_all_25_documents = pd.DataFrame({\"Received Texts\": twenty_five_closest_texts, \"Score\": scores})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_for_all_25_documents.sort_values(by=[\"Score\"], ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the score table above, we can observe that the top result (2nd row, index 0) returned by cosine distance is not as relevant compared to the first row (index 5). However, without reranking, the text at index 5 did not even make it into the top 3 when we only performed cosine distance retrieval directly from the vector database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag-retrieval-rerank-_oC8k4Cq-py3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
